# Spotify Churn Analysis Project

Este repositorio contiene un an√°lisis completo de predicci√≥n de abandono (churn) para usuarios de Spotify, utilizando un dataset sint√©tico. El proyecto abarca desde el an√°lisis exploratorio de datos (EDA) hasta la comparaci√≥n de modelos avanzados y an√°lisis de reducci√≥n de dimensionalidad.

## Tabla de Contenidos

- [Descripci√≥n](#-descripci√≥n)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [Instalaci√≥n y Configuraci√≥n](#Ô∏è-instalaci√≥n-y-configuraci√≥n)
- [Gu√≠a de Ejecuci√≥n](#-gu√≠a-de-ejecuci√≥n)
- [Notas Importantes](#Ô∏è-notas-importantes)

## Descripci√≥n

El objetivo principal es predecir si un usuario cancelar√° su suscripci√≥n bas√°ndose en caracter√≠sticas como tiempo de escucha, tipo de suscripci√≥n, interacci√≥n con anuncios, etc. Se han implementado y comparado m√∫ltiples modelos de Machine Learning (XGBoost, SVM, Random Forest, etc.) y estrategias de balanceo de clases (SMOTE).

## üìÇ Estructura del Proyecto

El flujo de trabajo est√° dividido en 5 notebooks secuenciales:

1. **`01-exploracion-eda.ipynb`**: An√°lisis Exploratorio de Datos (EDA). Carga de datos, an√°lisis de distribuciones, correlaciones y detecci√≥n de desbalance de clases.
2. **`02-estado-del-arte-plan.ipynb`**: Revisi√≥n del estado del arte y planificaci√≥n de la estrategia de modelado.
3. **`03-preprocesamiento-fe.ipynb`**: Limpieza de datos, codificaci√≥n de variables categ√≥ricas, escalado y Feature Engineering.
4. **`04-modelado-comparativo.ipynb`**: Entrenamiento y evaluaci√≥n comparativa de m√∫ltiples modelos (Logistic Regression, SVM, KNN, Decision Tree, Random Forest, XGBoost) bajo diferentes estrategias (Baseline, Class Weight, SMOTE).
5. **`05-reduccion-dimension.ipynb`**: An√°lisis de t√©cnicas de reducci√≥n de dimensionalidad (PCA, UMAP) y su impacto en el rendimiento de los mejores modelos.

Directorios adicionales:

- `data/`: Contiene el dataset (`spotify_churn_dataset.csv`), archivos intermedios y modelos entrenados (`.pkl`).
- `scripts/`: Scripts auxiliares de Python.

## Requisitos Previos

- **Conda** (Anaconda o Miniconda) instalado en su sistema.
- Git para clonar el repositorio.

## Instalaci√≥n y Configuraci√≥n

Siga estos pasos para configurar el entorno de desarrollo:

1. **Clonar el repositorio:**

   ```bash
   git clone https://github.com/AndresGUIO2/Churn-analysis
   cd ChurnAnalisys
   ```

2. **Crear el entorno virtual con Conda:**

   El archivo `environment.yml` contiene todas las dependencias necesarias (Python 3.12, pandas, scikit-learn, xgboost, statsmodels, umap-learn, etc.).

   ```bash
   conda env create -f environment.yml
   ```

3. **Activar el entorno:**

   ```bash
   conda activate churn
   ```

##  Gu√≠a de Ejecuci√≥n

Para reproducir los resultados, ejecute los notebooks en el siguiente orden estricto, ya que cada uno genera archivos que son consumidos por los siguientes:

1. Abra VS Code o Jupyter Lab en la ra√≠z del proyecto.
2. Seleccione el kernel del entorno `churn` que acaba de crear.
3. Ejecute paso a paso:
   - `01-exploracion-eda.ipynb` (Descarga el dataset y genera an√°lisis inicial)
   - `02-estado-del-arte-plan.ipynb` (Contexto te√≥rico)
   - `03-preprocesamiento-fe.ipynb` (Genera datasets procesados en `data/`)
   - `04-modelado-comparativo.ipynb` (Entrena modelos y guarda los mejores en `data/`)
   - `05-reduccion-dimension.ipynb` (Analiza PCA/UMAP usando los modelos guardados)

## ‚ö†Ô∏è Notas Importantes

- **Dataset Sint√©tico**: El dataset utilizado ([Spotify Analysis Dataset 2025](https://www.kaggle.com/datasets/nabihazahid/spotify-dataset-for-churn-analysis/data)) es generado sint√©ticamente. Los patrones y m√©tricas de rendimiento (F1-Score ~0.40) no deben extrapolarse directamente a escenarios de producci√≥n con datos reales.
- **Modelos**: Los archivos de modelos entrenados (`.pkl`) se guardan en la carpeta `data/`. Si no existen, debe ejecutar el notebook `04` para generarlos.
